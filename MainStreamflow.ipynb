{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.decomposition import PCA\n",
    "import time\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def onehotEncoding(dfWhole, feaName):\n",
    "    cats = list(np.unique(np.array(dfWhole[feaName])))\n",
    "    for cat in cats:\n",
    "        dfWhole[feaName + str(cat)] = dfWhole[feaName] == cat\n",
    "    return dfWhole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTrainOri = pd.read_csv(filepath_or_buffer='D:\\\\Workfiles\\\\Kaggle\\\\Porto Seguro Safe Driver Prediction\\\\data\\\\train.csv')\n",
    "dfTestOri = pd.read_csv(filepath_or_buffer='D:\\\\Workfiles\\\\Kaggle\\\\Porto Seguro Safe Driver Prediction\\\\data\\\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfWhole = pd.concat([dfTrainOri, dfTestOri])\n",
    "dfWhole.index = dfWhole['id']\n",
    "dfWhole = dfWhole.drop(['id'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################### onehot encoding ################################################\n",
    "feaToDelete = []\n",
    "for fea in dfWhole.columns:\n",
    "    if fea.split('_')[-1] == 'cat':\n",
    "        feaToDelete.append(fea)\n",
    "        dfWhole = onehotEncoding(dfWhole, fea)\n",
    "dfWhole = dfWhole.drop(feaToDelete, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################### train/dev set dividing #############################################\n",
    "isTest = pd.isnull(dfWhole['target'])\n",
    "isNotTest = ~pd.isnull(dfWhole['target'])\n",
    "numNotTest = np.sum(isNotTest)\n",
    "rateDev = 0.1\n",
    "numDev = int(numNotTest * rateDev)\n",
    "numTrain = numNotTest - numDev\n",
    "permut = np.random.permutation(numNotTest)\n",
    "\n",
    "dfNotTest = dfWhole.loc[isNotTest, :]\n",
    "dfTrainX = dfNotTest.iloc[permut[:numTrain], :]\n",
    "dfDevX = dfNotTest.iloc[permut[numTrain:], :]\n",
    "dfTrainY = dfTrainX['target']\n",
    "dfTrainX = dfTrainX.drop(['target'], axis = 1)\n",
    "dfDevY = dfDevX['target']\n",
    "dfDevX = dfDevX.drop(['target'], axis = 1)\n",
    "dfTestX = dfWhole.loc[isTest, :].drop(['target'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######################################## transform df into ar ##############################################\n",
    "arTrainX = np.array(dfTrainX).T\n",
    "arTrainY = np.array(dfTrainY).T.reshape([-1])\n",
    "arDevX = np.array(dfDevX).T\n",
    "arDevY = np.array(dfDevY).T.reshape([-1])\n",
    "arTestX = np.array(dfTestX).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explained_variance_ratio_: [ 0.1871453   0.11910895  0.10655399  0.10108749  0.07680283  0.05147351\n",
      "  0.0405334   0.03007437  0.02825043  0.02514396  0.02197689  0.02044376\n",
      "  0.0181996   0.0176244   0.01301997  0.01054684  0.00971028  0.00805745\n",
      "  0.00732174  0.00686088]\n",
      "sum of above: 0.899936022874\n"
     ]
    }
   ],
   "source": [
    "################################################## PCA #####################################################\n",
    "pca = PCA(n_components = 20)\n",
    "pca.fit(X = arTrainX.T)\n",
    "print(\"explained_variance_ratio_:\", pca.explained_variance_ratio_)\n",
    "print(\"sum of above:\", sum(pca.explained_variance_ratio_))\n",
    "arTrainX = pca.transform(arTrainX.T).T\n",
    "arDevX = pca.transform(arDevX.T).T\n",
    "arTestX = pca.transform(arTestX.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################## NN ######################################################\n",
    "layersize = [50, 1]\n",
    "layercount = len(layersize)\n",
    "\n",
    "seed = time.time()\n",
    "X = tf.placeholder(shape = [arTrainX.shape[0], None], dtype = 'float')\n",
    "Y_ = tf.placeholder(shape = [None], dtype = 'float')\n",
    "W = dict()\n",
    "b = dict()\n",
    "Y = dict()\n",
    "Y[0] = X\n",
    "layersizeTemp = [arTrainX.shape[0]] + layersize\n",
    "for i in range(layercount):\n",
    "    W[i+1] = tf.Variable(tf.random_normal(seed = np.random.randint(seed), shape = [layersizeTemp[i+1], layersizeTemp[i]]) * 1)\n",
    "    b[i+1] = tf.Variable(tf.zeros(shape = [layersizeTemp[i+1], 1]))\n",
    "    if i != layercount - 1:\n",
    "        Y[i+1] = tf.nn.relu(tf.matmul(W[i+1], Y[i]) + b[i+1])\n",
    "Y[layercount] = tf.nn.sigmoid(tf.matmul(W[layercount], Y[layercount-1]) + b[layercount])\n",
    "Youtput = Y[layercount]\n",
    "\n",
    "correct_prediction = tf.equal(tf.round(Youtput), Y_)\n",
    "correct_rate = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\n",
    "\n",
    "cost = tf.reduce_sum(tf.square(Youtput - Y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.776260941476 0.772651669159\n",
      "0.963544282058 0.963626283161\n",
      "0.963544282058 0.963626283161\n",
      "0.963544282058 0.963626283161\n",
      "0.963544282058 0.963626283161\n",
      "0.963544282058 0.963626283161\n",
      "0.963544282058 0.963626283161\n",
      "0.963544282058 0.963626283161\n",
      "0.963544282058 0.963626283161\n",
      "0.963544282058 0.963626283161\n",
      "0.963544282058 0.963626283161\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.AdamOptimizer(0.1).minimize(cost)\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init) \n",
    "\n",
    "for i in range(101):\n",
    "    #sess.run(train_step, feed_dict = {X:dpTrainX.getData(size=50), Y_:dpTrainY.getData(size=50)})\n",
    "    sess.run(optimizer, feed_dict = {X:arTrainX, Y_:arTrainY})\n",
    "    if i % 10 == 0:\n",
    "        predTrain = sess.run(Youtput, feed_dict={X:arTrainX, Y_: arTrainY})\n",
    "        predDev = sess.run(Youtput, feed_dict={X:arDevX, Y_: arDevY})\n",
    "        print(np.mean(np.round(predTrain).reshape([-1]) == arTrainY.reshape([-1])), np.mean(np.round(predDev).reshape([-1]) == arDevY.reshape([-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predTest = sess.run(Youtput, feed_dict={X:arTestX})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "predTrain = sess.run(Youtput, feed_dict={X:arTrainX, Y_: arTrainY})\n",
    "print(predTrain)\n",
    "print(np.sum(np.square(predTrain - np.mean(predTrain))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculateAuc(arTrainY.reshape([-1]), predTrain.reshape([-1])), calculateAuc(arDevY.reshape([-1]), predDev.reshape([-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel = 'rbf', gamma = 100, C = 50)\n",
    "clf.fit(arTrainX.T, arTrainY.reshape([-1]))\n",
    "predTrain = clf.predict(arTrainX.T)\n",
    "precisionTrain = sum(predTrain == arTrainY.reshape([-1])) / predTrain.shape[0]\n",
    "print(precisionTrain)\n",
    "predDev = clf.predict(arDevX.T)\n",
    "precisionDev = sum(predDev == arDevY.reshape([-1])) / predDev.shape[0]\n",
    "print(precisionDev)\n",
    "pred = clf.predict(arTestX.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################### save result to csvfile ########################################\n",
    "result = pd.DataFrame({'id':dfTestOri['id']} )\n",
    "result['target'] = predTest.reshape([-1])\n",
    "result.to_csv(path_or_buf='result\\\\result20171008_01.csv', header=True, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
